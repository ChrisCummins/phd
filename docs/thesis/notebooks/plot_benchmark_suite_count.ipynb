{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from labm8.py import app\n",
    "from labm8.py import viz\n",
    "\n",
    "FLAGS = app.FLAGS(['argv0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_review_url = \"https://raw.githubusercontent.com/ChrisCummins/paper-synthesizing-benchmarks/e8c17cbd9bf735d10c49563b13a91fcc33566936/data/lit-review.csv\"\n",
    "df = pd.read_csv(lit_review_url)\n",
    "\n",
    "# Hotfix for typo \"Ploybench\" in data file:\n",
    "df.loc[df[\"Benchmark Suite\"] == \"Ploybench\", [\"Benchmark Suite\"]] = \"Polybench\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of benchmarks per paper: 17.23\n",
      "Median number of benchmarks per paper:  14.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benchmark Suite</th>\n",
       "      <th>#. benchmarks per paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rodinia</td>\n",
       "      <td>6.674107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NVIDIA SDK</td>\n",
       "      <td>4.933036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMD SDK</td>\n",
       "      <td>4.352679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parboil</td>\n",
       "      <td>3.772321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NAS</td>\n",
       "      <td>2.205357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polybench</td>\n",
       "      <td>1.683036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SHOC</td>\n",
       "      <td>0.696429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ad-hoc</td>\n",
       "      <td>0.348214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISPASS</td>\n",
       "      <td>0.348214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lonestar</td>\n",
       "      <td>0.290179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SPEC-Viewperf</td>\n",
       "      <td>0.290179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARS</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPGPUsim</td>\n",
       "      <td>0.174107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Benchmark Suite  #. benchmarks per paper\n",
       "10         Rodinia                 6.674107\n",
       "7       NVIDIA SDK                 4.933036\n",
       "0          AMD SDK                 4.352679\n",
       "8          Parboil                 3.772321\n",
       "6              NAS                 2.205357\n",
       "9        Polybench                 1.683036\n",
       "11            SHOC                 0.696429\n",
       "1           Ad-hoc                 0.348214\n",
       "3           ISPASS                 0.348214\n",
       "4         Lonestar                 0.290179\n",
       "12   SPEC-Viewperf                 0.290179\n",
       "5             MARS                 0.232143\n",
       "2         GPGPUsim                 0.174107"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean(array):\n",
    "  \"\"\"\n",
    "  Return the mean value of a list of divisible numbers.\n",
    "  \"\"\"\n",
    "  n = len(array)\n",
    "\n",
    "  if n < 1:\n",
    "    return 0\n",
    "  elif n == 1:\n",
    "    return array[0]\n",
    "  return sum(array) / n\n",
    "\n",
    "\n",
    "def median(array):\n",
    "  \"\"\"\n",
    "  Return the median value of a list of numbers.\n",
    "  \"\"\"\n",
    "  n = len(array)\n",
    "\n",
    "  if n < 1:\n",
    "    return 0\n",
    "  elif n == 1:\n",
    "    return array[0]\n",
    "\n",
    "  sorted_vals = sorted(array)\n",
    "  midpoint = int(n / 2)\n",
    "  if n % 2 == 1:\n",
    "    return sorted_vals[midpoint]\n",
    "  else:\n",
    "    return (sorted_vals[midpoint - 1] + sorted_vals[midpoint]) / 2.0\n",
    "\n",
    "\n",
    "benchmark_counts = [x[1] for x in df.groupby(\"Paper\").size().iteritems()]\n",
    "suites = pd.DataFrame(\n",
    "    [(x[0], x[1] / mean(benchmark_counts))\n",
    "     for x in df.groupby([\"Benchmark Suite\"]).size().iteritems()],\n",
    "    columns=[\"Benchmark Suite\", \"#. benchmarks per paper\"])\n",
    "suites.sort_values(\"#. benchmarks per paper\", inplace=True, ascending=False)\n",
    "\n",
    "print(\"Average number of benchmarks per paper:\", round(mean(benchmark_counts), 2))\n",
    "print(\"Median number of benchmarks per paper: \", round(median(benchmark_counts), 2))\n",
    "print()\n",
    "suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"Benchmark Suite\", y=\"#. benchmarks per paper\", data=suites)\n",
    "# threshold for benchmark suites used in paper:\n",
    "plt.axhline(y=.5, color=\"k\", lw=1)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"\"); plt.ylabel(\"#. benchmarks used\")\n",
    "viz.Finalize(\"/tmp/motivation-c.pdf\", figsize=(5, 3), tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352678571428572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratio of results from top seven most popular benchmark suites:\n",
    "suites[:7][\"#. benchmarks per paper\"].sum() / suites[\"#. benchmarks per paper\"].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
