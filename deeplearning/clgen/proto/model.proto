// The file defines the protos for specificying CLgen models.
//
// Please ignore the "optional" proto syntax, ALL FIELDS MUST BE SET.
// This is to ensure consistent hashing of proto instances to a unique checksum,
// as default values are ommitted in serialized protos. Unfortunately, this
// means setting a value to any new field in all of the proto files across this
// entire repository (and any which are not tracked in this repo).
//
// Copyright (c) 2016, 2017, 2018, 2019 Chris Cummins.
//
// clgen is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// clgen is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.
//
// You should have received a copy of the GNU General Public License
// along with clgen.  If not, see <https://www.gnu.org/licenses/>.

syntax = "proto2";
package clgen;

option java_package = "deeplearning.clgen";

import "deeplearning/clgen/proto/corpus.proto";

// The specification of a CLgen model.
message Model {
  optional clgen.Corpus corpus = 1;
  optional NetworkArchitecture architecture = 2;
  optional TrainingOptions training = 3;
}

// The specification of a CLgen language model.
message NetworkArchitecture {
  enum Backend {
    TENSORFLOW = 0;
    KERAS = 1;
  }

  enum NeuronType {
    LSTM = 0;
    RNN = 1;
    GRU = 2;
  }

  optional Backend backend = 1;
  // The size of the input embedding layer. Only required if backend == KERAS.
  // Must be > 0.
  optional int32 embedding_size = 2;
  // The type of neuron. Valid options are: {"lstm","rnn","gru"}.
  optional NeuronType neuron_type = 3;
  // The number of neurons in each layer of the network.
  optional int32 neurons_per_layer = 4;
  // The total number of layers in the network.
  optional int32 num_layers = 5;
  // If greater than zero, this adds a dropout layer after each layer of neurons
  // with probability post_alyer_drop_micros / 1000000. E.g. a value of 2000
  // would insert a dropout with probability of 0.2.
  optional int32 post_layer_dropout_micros = 6;
}

// Options used for training a CLgen language model.
message TrainingOptions {
  // The number of epochs to train the network for.
  optional int32 num_epochs = 1;
  // The length of training sequences.
  optional int32 sequence_length = 2;
  // If true, shuffle the order of contentfiles in the corpus between each
  // training epoch.
  optional bool shuffle_corpus_contentfiles_between_epochs = 3;
  // The training batch size. Note that this is only a *requested* batch size,
  // there may be cases where the runtime decides to modify this value. For
  // example, when the corpus size is smaller than the batch size. Any changes
  // to this value at runtime will be logged as errors.
  optional int32 batch_size = 4;
  // The optimizer configuration.
  oneof optimizer {
    AdamOptimizer adam_optimizer = 10;
    RmsPropOptimizer rmsprop_optimizer = 11;
  };
}

// The field name suffix '_micros' shows that the value contained in the field
// is converted at runtime to a floating point number by dividing it by 1e6.
// The reason for _micros fields is so that we can realiably encode and compare
// protos without having to worry about floating point rounding and comparisons.

message AdamOptimizer {
  // The initial learning rate. Must be >= 0. A recommended starting value is
  // 2000 (i.e. real value 0.002).
  optional int32 initial_learning_rate_micros = 1;
  // The ratio by which the learning rate decays per epoch of training. Must be
  // >= 0. A recommended starting value is 5000 (i.e. real value 0.05).
  optional int32 learning_rate_decay_per_epoch_micros = 2;
  // Must be in real value range 0 < beta_1 < 1. A recommended starting value
  // is 900000 (i.e. real value 0.9).
  optional int32 beta_1_micros = 3;
  // Must be in real value range 0 < beta_2 < 1. A recommended starting value
  // is 999000 (i.e. real value 0.999).
  optional int32 beta_2_micros = 4;
  // The normalized gradient clip value. A recommended starting value is 5000000
  // (ie. real value 5.0).
  optional int32 normalized_gradient_clip_micros = 5;
}

message RmsPropOptimizer {
  // The initial learning rate. Must be >= 0. A recommended starting value is
  // 1000 (i.e. real value 0.001).
  optional int32 initial_learning_rate_micros = 1;
  // The ratio by which the learning rate decays per epoch of training. Must be
  // >= 0. A recommended starting value is 0.
  optional int32 learning_rate_decay_per_epoch_micros = 2;
}

// A generated sample. Instances of this proto are returned by a Model's
// Sample() method.
message Sample {
  optional string text = 1;
  optional int32 sample_time_ms = 2;
  // Sampling may be batches, so that the sum of sample_time_ms over a range
  // of samples may be much higher than the actual amount of time required to
  // sample the set. This field contains the number of milliseconds between the
  // last sample completing and this sample completing, so that by summing
  // wall_time_ms, it is possible to get an accurate idea of the actual time
  // taken to produce a set of samples.
  optional int32 wall_time_ms = 3;
  optional int64 sample_start_epoch_ms_utc = 4;
  optional int32 num_tokens = 5;
}
