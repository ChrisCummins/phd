"""Library that handles custom stuff for working with this project."""
import datetime
import git
import typing
import pathlib
import subprocess
import re
import stat
import os
import glob

import getconfig
from labm8 import app
from labm8 import bazelutil
from labm8 import humanize
from tools.source_tree import source_tree

FLAGS = app.FLAGS

# A list of relative paths to include in every export of this project. Glob
# patterns are expanded.
_ALWAYS_EXPORTED_FILES = [
    '.bazelrc',  # Not strictly required, but provides consistency.
    'configure',  # Needed to generate config proto.
    'BUILD',  # Top-level BUILD file is always needed.
    'WORKSPACE',  # Implicit dependency of everything.
    'README.md',
    'tools/bzl/*',  # Implicit dependency of WORKSPACE file.
    'tools/BUILD',  # Needed by //tools/bzl:maven_jar.bzl.
    'tools/download_file.py',  # Needed by //tools/bzl:maven_jar.bzl.
    'tools/util.py',  # Needed by //tools:download_file.py.
    'third_party/*.BUILD',  # Implicit dependencies of WORKSPACE file.
    'third_party/py/tensorflow/BUILD.in',  # Needed by ./configure
    'tools/workspace_status.sh',  # Needed by .bazelrc
    # tools/requirements.txt is always needed, but is handled separately.
]

# A list of relative paths to files which are excluded from export. Glob
# patterns are NOT supported.
_NEVER_EXPORTED_FILES = [
    'config.pbtxt',  # Generated by ./configure
    'third_party/py/tensorflow/BUILD',  # Generated by ./configure
]

_BAZEL_WRAPPER = bazelutil.DataString(
    'phd/tools/source_tree/data/bazel_wrapper.py')


class PhdWorkspace(bazelutil.Workspace):

  def __init__(self, *args, **kwargs):
    super(PhdWorkspace, self).__init__(*args, **kwargs)
    self._repo = git.Repo(self.workspace_root)
    if not (self.workspace_root / 'tools' / 'requirements.txt').is_file():
      raise OSError("Expected file toos/requirements.txt not found")

  @property
  def git_repo(self) -> git.Repo:
    return self._repo

  def GetAlwaysExportedFiles(self) -> typing.Iterable[str]:
    """Get hardcoded additional files to export."""
    relpaths = []
    for p in _ALWAYS_EXPORTED_FILES:
      abspaths = glob.glob(f'{self.workspace_root}/{p}')
      relpaths += [
          os.path.relpath(path, self.workspace_root) for path in abspaths
      ]
    return relpaths

  def GetAuxiliaryExportFiles(self, paths: typing.Set[str]) -> typing.List[str]:
    """Get a list of auxiliary files to export."""

    def GlobToPaths(glob_pattern: str) -> typing.List[str]:
      abspaths = glob.glob(glob_pattern)
      return [os.path.relpath(path, self.workspace_root) for path in abspaths]

    auxiliary_exports = []
    for path in paths:
      dirname = (self.workspace_root / path).parent
      auxiliary_exports += GlobToPaths(f'{dirname}/DEPS.txt')
      auxiliary_exports += GlobToPaths(f'{dirname}/README*')
      auxiliary_exports += GlobToPaths(f'{dirname}/LICENSE*')

    return auxiliary_exports

  def FilterExcludedPaths(
      self, paths: typing.List[pathlib.Path]) -> typing.Iterable[pathlib.Path]:
    return [path for path in paths if path not in _NEVER_EXPORTED_FILES]

  def GetAllSourceTreeFiles(
      self, targets: typing.List[str],
      file_copy_mapping: typing.Dict[str, str]) -> typing.List[pathlib.Path]:
    """Get the full list of source files to export for targets."""
    file_set = set(file_copy_mapping.values())
    for target in targets:
      file_set = file_set.union(set(self.GetDependentFiles(target)))
      file_set = file_set.union(set(self.GetBuildFiles(target)))
      file_set = file_set.union(set(self.GetDependentFiles(target)))
      file_set = file_set.union(set(self.GetDependentFiles(target)))

    file_set = file_set.union(set(self.GetAlwaysExportedFiles()))
    file_set = file_set.union(set(self.GetAuxiliaryExportFiles(file_set)))
    filtered_files = self.FilterExcludedPaths(file_set)
    return list(sorted(filtered_files))

  def GetPythonRequirementsForTarget(
      self, targets: typing.List[str]) -> typing.List[str]:
    """Get the subset of requirements.txt which is needed for a target."""
    # The set of bazel dependencies for all targets.
    dependencies = set()
    for target in targets:
      bazel = self.BazelQuery([f'deps({target})'], stdout=subprocess.PIPE)
      grep = subprocess.Popen(['grep', '^@pypi__'],
                              stdout=subprocess.PIPE,
                              stdin=bazel.stdout,
                              universal_newlines=True)
      stdout, _ = grep.communicate()
      if bazel.returncode:
        raise OSError("bazel query failed")
      output = stdout.rstrip()
      if output:
        dependencies = dependencies.union(set(output.split('\n')))

    with open(self.workspace_root / 'tools/requirements.txt') as f:
      all_requirements = set(f.readlines())

    needed = []
    all_dependencies = set()
    # This is a pretty hacky approach that tries to match the package component
    # of the generated @pypi__<package>_<vesion> package to the name as it
    # appears in tools/requirements.txt.
    for dependency in dependencies:
      if not dependency.startswith('@pypi__'):
        continue
      dependency = dependency[len('@pypi__'):].lower().split('//:')[0]
      all_dependencies.add(dependency)

    def _GetMatchingRequirements(dependency: str, all_requirements):
      requirements = []
      for requirement in all_requirements:
        requirement_to_match = requirement.replace('-', '_').lower().rstrip()
        requirement_to_match = requirement_to_match.split('==')[0]
        requirement_to_match = re.sub(r'#.*', '', requirement_to_match)
        if not requirement_to_match:
          continue
        if dependency.startswith(requirement_to_match):
          requirements.append(requirement)
      return requirements

    for dependency in all_dependencies:
      requirements = _GetMatchingRequirements(dependency, all_requirements)
      if not requirements:
        continue
      needed += requirements
      # Total hack workaround for the fact that
      # //third_party/py/scipy:BUILD pulls in multiple packages.
      for requirement in requirements:
        if requirement.startswith('scipy'):
          needed += _GetMatchingRequirements('scikit', all_requirements)

    return list(sorted(set(needed)))

  def CreateBazelWrapperForExports(self, workspace: bazelutil.Workspace,
                                   targets: typing.List[str]) -> None:
    """Create a 'bazel_wrapper.py' script in the root of the destination tree.

    The bazel_wrapper.py script checks that any targets passed to bazel were part
    of the original export set.
    """
    print('bazel_wrapper.py')

    all_targets = set()
    for target in targets:
      bazel = self.BazelQuery([target],
                              stdout=subprocess.PIPE,
                              universal_newlines=True)
      stdout, _ = bazel.communicate()
      if bazel.returncode:
        raise OSError("bazel query failed")
      output_lines = stdout.rstrip().split('\n')
      all_targets = all_targets.union(set(output_lines))

    if not all_targets:
      raise ValueError("No targets found?")
    targets_str = ',\n    '.join([f"'{x}'" for x in sorted(all_targets)])
    wrapper = _BAZEL_WRAPPER.replace('# @EXPORTED_TARGETS@ #', targets_str)
    with open(workspace.workspace_root / 'bazel_wrapper.py', 'w') as f:
      f.write(wrapper)
    # Set the executable bit.
    st = os.stat(workspace.workspace_root / 'bazel_wrapper.py')
    os.chmod(workspace.workspace_root / 'bazel_wrapper.py',
             st.st_mode | stat.S_IEXEC)

  def AddBazelWrapperPrefixToReadme(self, workspace: bazelutil.Workspace,
                                    targets: typing.List[str]) -> None:
    """Prepend a header to the README.md with bazel-wrapper details."""
    phd_repo = git.Repo(path=getconfig.GetGlobalConfig().paths.repo_root)
    parent_hash = phd_repo.head.object.hexsha
    with open(self.workspace_root / 'README.md') as f:
      readme = f.read()

    targets_str = '\n  '.join(
        [f'./bazel_wrapper.py build {x}' for x in targets])
    readme = f"""# Subtree export from [phd](https://github.com/ChrisCummins/phd)

  This repository was automatically generated by
  [//tools/source_tree:export_source_tree](https://github.com/ChrisCummins/phd/blob/master/tools/source_tree/export_source_tree.py)
  at {datetime.datetime.now()} from
  [{parent_hash}](https://github.com/ChrisCummins/phd/commit/{parent_hash}).
  It contains only the dependencies required for the following bazel targets:

  ```
    {targets_str}
  ```

  To report issues, contribute patches, or use other targets,
  please use the [parent repository](https://github.com/ChrisCummins/phd).

  Begin original README:

  """ + readme

    with open(self.workspace_root / 'README.md', 'w') as f:
      f.write(readme)

  def CreatePythonRequirementsFileForTargets(
      self, workspace: bazelutil.Workspace, targets: typing.List[str]) -> None:
    # Export the subset of python requirements that are needed.
    print('tools/requirements.txt')
    requirements = self.GetPythonRequirementsForTarget(targets)
    requirements_path = (workspace.workspace_root / 'tools' /
                         'requirements.txt')
    with open(requirements_path, 'w') as f:
      print(''.join(requirements), file=f)

  def CopyFilesToDestination(self, workspace: bazelutil.Workspace,
                             file_copy_mapping: typing.Dict[str, str]) -> None:
    for src_relpath, dst_relpath in file_copy_mapping.items():
      src_path = self.workspace_root / src_relpath
      dst_path = workspace.workspace_root / dst_relpath

      if not src_path.is_file():
        raise OSError(f"File `{file_to_copy}` not found")

      dst_path.parent.mkdir(exist_ok=True, parents=True)
      print(dst_relpath)
      shutil.copy(src_path, dst_path)

  def ExportToRepo(self, repo: git.Repo, targets: typing.List[str],
                   file_copy_mapping: typing.Dict[str, str]) -> None:
    """Export the requested targets to the destination directory."""
    # The timestamp for the export.
    timestamp = datetime.datetime.utcnow()

    # Export the git history.
    src_files = self.GetAllSourceTreeFiles(targets, file_copy_mapping)
    app.Log(1, 'Exporting git history for %s files',
            humanize.Commas(len(src_files)))
    for file in src_files:
      print(file)
    source_tree.ExportGitHistoryForFiles(self.git_repo, repo, src_files)

    # Make manual adjustments.
    exported_workspace = bazelutil.Workspace(pathlib.Path(
        repo.working_tree_dir))
    self.CreatePythonRequirementsFileForTargets(exported_workspace, targets)
    self.CreateBazelWrapperForExports(exported_workspace, targets)
    self.AddBazelWrapperPrefixToReadme(exported_workspace, targets)
    # Copy the extra files last so that we can trample over the generated
    # README file if required.
    self.CopyFilesToDestination(exported_workspace, file_copy_mapping)

    if not repo.is_dirty(untracked_files=True):
      return

    app.Log(1, 'Creating automated subtree export commit')
    repo.git.add('.')
    author = git.Actor(name='[Git export bot]', email='/dev/null')
    repo.index.commit(f'Automated subtree export at {timestamp.isoformat()}',
                      author=author,
                      committer=author,
                      skip_hooks=True)
