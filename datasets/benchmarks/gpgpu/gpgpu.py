"""A collection of seven GPGPU benchmark suites.

These seven benchmark suites were responsible for 92% of GPU results published
in 25 top tier conference papers. For more details, see:

  ï»¿Cummins, C., Petoumenos, P., Zang, W., & Leather, H. (2017). Synthesizing
  Benchmarks for Predictive Modeling. In CGO. IEEE.

When executed as a binary, this file runs the selected benchmark suites and
dumps the execution logs generated by libcecl in a directory.

Usage:

  bazel run //datasets/benchmarks/gpgpu -- --gpgpu_device_types=oclgrind
      --gpgpu_benchmarks_suites=npb-3.3 --gpgpu_outdir=/tmp/logs
"""
import contextlib
import functools
import multiprocessing
import os
import pathlib
import subprocess
import tempfile
import typing

from absl import app
from absl import flags
from absl import logging

from gpu.oclgrind import oclgrind
from labm8 import bazelutil
from labm8 import fs
from labm8 import labdate
from labm8 import labtypes
from labm8 import system


FLAGS = flags.FLAGS

# The list of all GPGPU benchmark suites.
_BENCHMARK_SUITE_NAMES = [
  'amd-app-sdk-3.0',
  'npb-3.3',
  'nvidia-4.2',
  'parboil-0.2',
  'polybench-gpu-1.0',
  'rodinia-3.1',
  'shoc-1.1.5',
  'dummy_just_for_testing',
]

flags.DEFINE_list('gpgpu_benchmark_suites', _BENCHMARK_SUITE_NAMES,
                  'The names of benchmark suites to run. Defaults to all '
                  'benchmark suites.')
flags.DEFINE_list('gpgpu_device_types', ['oclgrind'],
                  'The device types to execute benchmark suites on. One or '
                  'more of {cpu,gpu,oclgrind}.')
flags.DEFINE_string('gpgpu_outdir', '/tmp/datasets/benchmarks/gpgpu',
                    'The directory to write log files to.')
flags.DEFINE_integer('gpgpu_build_process_count', multiprocessing.cpu_count(),
                     'The number of parallel threads to use when building '
                     'GPGPU benchmark suites. Defaults to the number of '
                     'processors on your system.')

# The path of libcecl directory, containing the libcecl header, library, and
# run script.
_LIBCECL = bazelutil.DataPath('phd/gpu/libcecl/libcecl.so')
_LIBCECL_HEADER = bazelutil.DataPath('phd/gpu/libcecl/libcecl.h')

# Path to OpenCL headers and library.
_OPENCL_HEADERS_DIR = bazelutil.DataPath('opencl_120_headers')
if system.is_linux():
  _LIBOPENCL_DIR = bazelutil.DataPath('libopencl')

_DUMMY_BENCHMARK = bazelutil.DataPath(
    'phd/datasets/benchmarks/gpgpu/dummy_just_for_testing/dummy_benchmark')

_RODINIA_DATA_ROOT = bazelutil.DataPath('rodinia_data')


def CheckCall(command: typing.Union[str, typing.List[str]],
              shell: bool = False, env: typing.Dict[str, str] = None):
  """Wrapper around subprocess.check_call() to log executed commands."""
  if shell:
    logging.debug('$ %s', command)
    subprocess.check_call(command, shell=True, env=env)
  else:
    command = [str(x) for x in command]
    logging.debug('$ %s', ' '.join(command))
    subprocess.check_call(command, env=env)


def RewriteClDeviceType(device_type: str, path: pathlib.Path):
  """Rewrite all instances of CL_DEVICE_TYPE_XXX in the given path."""
  cl_device_type = {
    'cpu': 'CL_DEVICE_TYPE_CPU',
    'gpu': 'CL_DEVICE_TYPE_GPU',
    'oclgrind': 'CL_DEVICE_TYPE_CPU',
  }[device_type]
  CheckCall(f"""\
for f in $(find '{path}' -type f); do
  grep CL_DEVICE_TYPE_ $f &>/dev/null && {{
    sed -E -i 's/CL_DEVICE_TYPE_[A-Z]+/{cl_device_type}/g' $f
    echo Set {cl_device_type} in $f
  }}
done""", shell=True)


@functools.lru_cache(maxsize=1)
def OpenClCompileAndLinkFlags() -> typing.Tuple[str, str]:
  """Get device-specific OpenCL compile and link flags."""
  if system.is_linux():
    return (f'-isystem {_OPENCL_HEADERS_DIR}',
            f'-L{_LIBOPENCL_DIR} -Wl,-rpath,{_LIBOPENCL_DIR} -lOpenCL')
  else:
    return f'-isystem {_OPENCL_HEADERS_DIR}', '-framework OpenCL'


@contextlib.contextmanager
def MakeEnv(make_dir: pathlib.Path) -> typing.Dict[str, str]:
  """Return a build environment for GPGPU benchmarks."""
  cflags, ldflags = OpenClCompileAndLinkFlags()

  with fs.chdir(make_dir):
    with tempfile.TemporaryDirectory(prefix='phd_gpu_libcecl_header_') as d:
      fs.cp(_LIBCECL_HEADER, pathlib.Path(d) / 'cecl.h')

      env = os.environ.copy()
      env['CFLAGS'] = f'-isystem {d} {cflags}'
      env['LDFLAGS'] = f'-lcecl -L{_LIBCECL.parent} {ldflags}'
      yield env


def Make(target: str, make_dir: pathlib.Path) -> None:
  """Run make target in the given path."""
  if not (make_dir / 'Makefile').is_file():
    raise EnvironmentError(f"Cannot find Makefile in {make_dir}")

  # Build relative to the path, rather than using `make -c <path>`. This is
  # because some of the source codes have hard-coded relative paths.
  with MakeEnv(make_dir) as env:
    logging.debug('Running make %s in %s', target, make_dir)
    CheckCall(['make', target, '-j', FLAGS.gpgpu_build_process_count], env=env)


def FindExecutableInDir(path: pathlib.Path) -> pathlib.Path:
  """Find an executable file in a directory."""
  exes = [f for f in path.iterdir() if f.is_file() and os.access(f, os.X_OK)]
  if len(exes) != 1:
    raise EnvironmentError(f"Expected a single executable, found {len(exes)}")
  return exes[0]


@contextlib.contextmanager
def RunEnv(path: pathlib.Path) -> typing.Dict[str, str]:
  """Return an execution environment for a GPGPU benchmark."""
  with fs.chdir(path):
    env = os.environ.copy()
    env['LD_LIBRARY_PATH'] = _LIBCECL.parent
    env['DYLD_LIBRARY_PATH'] = _LIBCECL.parent
    yield env


class _BenchmarkSuite(object):
  """Abstract base class for a GPGPU benchmark suite.

  A benchmark suite provides two methods: ForceDeviceType(), which forces all
  of the benchmarks within the suite to execute on a given device type (CPU or
  GPU), and Run(), which executes the benchmarks and logs output to a directory.
  Example usage:

    with SomeBenchmarkSuite() as bs:
      bs.ForceDeviceType('gpu')
      bs.Run('/tmp/logs/gpu')
      bs.ForceDeviceType('cpu')
      bs.Run('/tmp/logs/cpu/1')
      bs.Run('/tmp/logs/cpu/2')
  """

  def __init__(self):
    if self.name not in _BENCHMARK_SUITE_NAMES:
      raise ValueError(f"Unknown benchmark suite: {self.name}")

    self._device_type = None
    self._input_files = bazelutil.DataPath(
        f'phd/datasets/benchmarks/gpgpu/{self.name}')
    self._mutable_location = None
    self._logdir = None

  def __enter__(self) -> pathlib.Path:
    prefix = f'phd_datasets_benchmarks_gpgpu_{self.name}'
    self._mutable_location = pathlib.Path(tempfile.mkdtemp(prefix=prefix))
    fs.cp(self._input_files, self._mutable_location)
    return self

  def __exit__(self, *args):
    fs.rm(self._mutable_location)
    self._mutable_location = None

  @property
  def path(self):
    """Return the path of the mutable copy of the benchmark sources."""
    if self._mutable_location is None:
      raise TypeError("Must be used as a context manager")
    return self._mutable_location

  def ForceDeviceType(self, device_type: str) -> None:
    """Force benchmarks to execute with the given device type."""
    if device_type not in {'cpu', 'gpu', 'oclgrind'}:
      raise ValueError(f"Unknown device type: {device_type}")
    self._device_type = device_type
    return self._ForceDeviceType(device_type)

  @property
  def device_type(self) -> str:
    return self._device_type

  def Run(self, logdir: pathlib.Path) -> None:
    """Run benchmarks and log results to directory."""
    logdir.mkdir(parents=True, exist_ok=True)
    if self.device_type is None:
      raise TypeError("Must call ForceDeviceType() before Run()")
    self._logdir = logdir
    ret = self._Run()
    self._logdir = None
    return ret

  def _ExecToLogFile(self, executable: pathlib.Path,
                     benchmark_name: str,
                     command: typing.Optional[typing.List[str]] = None) -> None:
    """Run executable using runcecl script and log output."""
    logging.info('Executing benchmark %s', benchmark_name)
    self._logdir.mkdir(exist_ok=True, parents=True)

    # Create the name of the logfile now, so that is timestamped to the start of
    # execution.
    log_name = '.'.join([
      self.name,
      benchmark_name,
      self.device_type,
      system.HOSTNAME,
      str(labdate.MillisecondsTimestamp()),
      'txt'
    ])

    # Assemble the command to run.
    command = command or [executable]
    if self.device_type == 'oclgrind':
      command = [str(oclgrind.OCLGRIND_PATH)] + command

    with RunEnv(executable.parent) as env:
      process = subprocess.Popen(command, env=env, stderr=subprocess.PIPE,
                                 universal_newlines=True)
      _, stderr = process.communicate()

      if process.returncode:
        raise OSError(
            f'Process failed with returncode {process.returncode} and '
            f'stderr: `{stderr}`')

      with open(self._logdir / log_name, 'w') as f:
        for line in stderr.split('\n'):
          if line.startswith('[CECL] '):
            print(line[len('[CECL] '):], file=f)

  # Abstract attributes that must be provided by subclasses.

  @property
  def name(self) -> str:
    raise NotImplementedError("abstract property")

  @property
  def benchmarks(self) -> typing.List[str]:
    """Return a list of all benchmark names."""
    raise NotImplementedError("abstract property")

  def _ForceDeviceType(self, device_type: str) -> None:
    """Set the given device type."""
    raise NotImplementedError("abstract method")

  def _Run(self) -> None:
    """Run the benchmarks and produce output log files."""
    raise NotImplementedError("abstract method")


class DummyJustForTesting(_BenchmarkSuite):
  """A dummy benchmark suite for testing purposes.

  It sill behaves like a real benchmark suite, but without running any expensive
  binaries.
  """

  @property
  def name(self) -> str:
    return "dummy_just_for_testing"

  @property
  def benchmarks(self) -> typing.List[str]:
    return ["dummy_benchmark"]

  def _ForceDeviceType(self, device_type: str):
    logging.info("Dummy benchmarks switching to %s", device_type)

  def _Run(self):
    logging.info("Executing dummy benchmarks!")
    self._ExecToLogFile(_DUMMY_BENCHMARK, 'dummy_benchmark')


class AmdAppSdkBenchmarkSuite(_BenchmarkSuite):
  """The AMD App SDK benchmarks."""

  @property
  def name(self):
    return 'amd-app-sdk-3.0'


class PolybenchGpuBenchmarkSuite(_BenchmarkSuite):
  """PolyBench/GPU 1.0 Benchmarks."""

  @property
  def name(self):
    return 'polybench-gpu-1.0'

  @property
  def benchmarks(self) -> typing.List[str]:
    return [
      '2DCONV',
      '2MM',
      '3DCONV',
      '3MM',
      'ATAX',
      'BICG',
      'CORR',
      'COVAR',
      # Bad: 'FDTD-2D',
      'GEMM',
      'GESUMMV',
      'GRAMSCHM',
      'MVT',
      'SYR2K',
      'SYRK',
    ]

  def _ForceDeviceType(self, device_type: str):
    RewriteClDeviceType(device_type, self.path / 'OpenCL')
    for benchmark in self.benchmarks:
      logging.info('Building benchmark %s', benchmark)
      Make('clean', self.path / 'OpenCL' / benchmark)
      Make('all', self.path / 'OpenCL' / benchmark)

  def _Run(self):
    for benchmark in self.benchmarks:
      executable = FindExecutableInDir(self.path / 'OpenCL' / benchmark)
      self._ExecToLogFile(executable, benchmark)


class RodiniaBenchmarkSuite(_BenchmarkSuite):
  """Rodinia Benchmark Suite 3.1.

  The University of Virginia Rodinia Benchmark Suite is a collection of parallel
  programs which targets heterogeneous computing platforms with both multicore
  CPUs and GPUs.

  Copyright (c)2008-2011 University of Virginia.

  For further details, see:

      S. Che, M. Boyer, J. Meng, D. Tarjan, J. W. Sheaffer, Sang-Ha Lee and
      K. Skadron. "Rodinia: A Benchmark Suite for Heterogeneous Computing".
      IISWC, 2009.
  """

  @property
  def name(self) -> str:
    return 'rodinia-3.1'

  @property
  def benchmarks(self) -> typing.List[str]:
    return [
      'b_tree',
      'backprop',
      'bfs',
      'cfd',
      'dwt2d',
      'gaussian',
      'heartwall',
      'hotspot',
      'hotspot3D',
      'hybridsort',
      'kmeans',
      'lavaMD',
      'leukocyte',
      'lud',
      'myocyte',
      'nn',
      'nw',
      'particlefilter',
      'pathfinder',
      'srad',
      'streamcluster',
    ]

  def _ForceDeviceType(self, device_type: str):
    RewriteClDeviceType(device_type, self.path / 'opencl')
    logging.info("Building Rodinia benchmarks")

    # This directory is not generated by the Makefile, but is needed by it.
    (self.path / 'bin/linux/opencl').mkdir(parents=True, exist_ok=True)

    Make('OCL_clean', self.path)
    Make('OPENCL', self.path)
    # TODO(cec): Original script then deleted the opencl/hotspot3D/3D file. Is
    # it not working?

    # Replace all of the @RODINIA_DATA_ROOT@ placeholders with the real path.
    CheckCall(f"""\
for f in $(find '{self.path}' -type f); do
  grep '@RODINIA_DATA_ROOT@' $f &>/dev/null && {{
    sed -E -i 's,@RODINIA_DATA_ROOT@,{_RODINIA_DATA_ROOT},g' $f
    echo Set @RODINIA_DATA_ROOT@ in $f
  }}
done""", shell=True)

  def _Run(self):
    for benchmark in self.benchmarks:
      executable = self.path / 'opencl' / benchmark / 'run'
      self._ExecToLogFile(executable, benchmark, command=['bash', './run'])


# A map of benchmark suite names to classes.
BENCHMARK_SUITES = {
  bs().name: bs for bs in labtypes.AllSubclassesOfClass(_BenchmarkSuite)
}


def main(argv: typing.List[str]):
  """Main entry point."""
  if len(argv) > 1:
    raise app.UsageError("Unknown arguments: '{}'.".format(' '.join(argv[1:])))

  # Run the requested benchmark suites on the requested devices.
  outdir = pathlib.Path(FLAGS.gpgpu_outdir)
  for benchmark_suite_name in FLAGS.gpgpu_benchmark_suites:
    benchmark_suite_class = BENCHMARK_SUITES.get(benchmark_suite_name)
    if not benchmark_suite_class:
      logging.fatal(
          f'Unknown benchmark suite. Legal values: {BENCHMARK_SUITES.keys()}')

    with benchmark_suite_class() as benchmark_suite:
      for device_type in FLAGS.gpgpu_device_types:
        logging.info('Building and running %s on %s', benchmark_suite.name,
                     device_type)
        benchmark_suite.ForceDeviceType(device_type)
        benchmark_suite.Run(outdir)


if __name__ == '__main__':
  app.run(main)
