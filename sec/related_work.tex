\section{Related Work} \label{sec:rw}

% Our work lies at the intersection of a number of areas: machine learning for code optimization, feature representation and engineering, and learning over source code.

% \paragraph{Machine learning for code optimization}

Machine learning has emerged as a viable means in automatically constructing heuristics for code optimization~\cite{Stephenson2005,Agakov,Wang2010,Kulkarni2012,Ding2015,Muralidharan2016}. Its great advantage is that it can adapt to changing hardware platforms as it has no a priori assumptions about their behavior. The success of machine learning based code optimization requires having a set of high-quality features that can capture the important characteristics of the target program. Given that there is an infinite number of these potential features, finding the right set of features is a non-trivial, time-consuming task. 

% \paragraph{Feature representations}

Various forms of program features have been used in compiler-based machine learning. These include static code structures~\cite{Jiang2010} and runtime information such as system load~\cite{Wen2015} and performance counters~\cite{Dubach2009}. In compiler research, the feature sets used for predictive models are often provided without explanation and rarely is the quality of those features evaluated. More commonly, an initial large, high dimensional candidate feature space is pruned via feature selection~\cite{Stephenson2005}, or projected into a lower dimensional space~\cite{Collins2013,Dubach2007}. FEAST employs a range of existing feature selection methods to select useful candidate features~\cite{Ting2016}. Unlike these approaches, \DeepTune extracts features and reduces the dimensionality of the feature space completely internally and without expert guidance. 

Park \emph{et al.} present a unique graph-based approach for feature representations~\cite{Park2012}. They use a Support Vector Machine where the kernel is based on graph similarity metric. Their technique still requires hand coded features at the basic block level, but thereafter, graph similarity against each of the training programs takes the place of global features. Being a kernel method, it requires that training data graphs be shipped with the compiler, which may not scale as the size of the training data grows with the number of instances, and some training programs may be very large. Finally, their graph matching metric is expensive, requiring $O(n^3)$ to compare against each training example. By contrast, our method does not need any hand built static code features, and both the deployment memory footprint and prediction time complexity are constant, regardless of the size of the training set. 

A few methods have been proposed to automatically generate features from the compiler's intermediate representation~\cite{Namolaru2010a,Leather2014}. These approaches closely tie the implementation of the predictive model to the compiler IR, which means changes to the IR will require modifications to the model. The work of \cite{Leather2014} uses genetic programming to search for features, and required a huge grammar to be written, some 160kB in length. Although much of this can be created from templates, selecting the right range of capabilities and search space bias is non trivial and up to the expert. The work of \cite{Namolaru2010a} expresses the space of features via logic programming over relations that represent information from the IRs. It greedily searches for expressions that represent good features. However, their approach relies on expert selected relations, combinators and constraints to work. For both approaches, the search time may be significant.

Cavazos \emph{et al.\ }present a reaction-based predictive model for software-hardware co-design~\cite{Cavazos2006}. Their approach profiles the target program using several carefully selected compiler options to see how program runtime changes under these options for a given micro-architecture setting. They then use the program ``reactions" to predict the best available application speedup. While their approach does not use static code features, developers must carefully select a few settings from a large number of candidate options for profiling, because poorly chosen options can significantly affect the quality of the model. Moreover, the program must be run several times before optimization, while our technique does not require the program to be profiled.

% \paragraph{Feature engineering}

% \paragraph{Learning over source code}
In recent years, machine learning techniques have been employed to model and learn from program source code on various tasks. These include mining coding conventions~\cite{Allamanis2014a} and idioms~\cite{Allamanis2014}, API example codes~\cite{Zhang2015a} and pseudo-code generation~\cite{Oda2015}, and benchmark generation~\cite{Cummins2017a}. Our work is the first attempt to extend the already challenging task of modeling distributions over source code to learning distributions over source code with respect to code optimizations.

Recently, deep neural networks~\cite{LeCun2015} have been shown to be a powerful tool for feature engineering in various tasks including image recognition~\cite{Krizhevsky2012,He2016} and audio processing~\cite{Lee2009b}. In the field of compiler optimization, no work so far has applied deep neural networks for program feature generation and selection. Our work is the first to do so.

%In a recent work~\cite{Bunel2017a}, Bunel \emph{et al.} formulate code super-optimization as a stochastic search problem to learn the distribution of different code transformations and expected performance improvement. As acknowledged by the authors, their approach can be improved by having temporal information of the code structures, for which \DeepTune can help. \review{ZW: CC--Check the last two sentences.}

%\paragraph{Reduce the cost of compiler-based machine learning}

%Leather \emph{et al.} describe an automatic approach to feature selection in~\cite{Leather2014}. A feature grammar is
%used to construct a search space of possible features, then genetic programming is used to explore the space, finding
%the feature set which provides the greatest performance. The quality of results is now dependent on the grammar, which
%ties the approach to a specific internal compiler representation. Changes to the compiler IR will require changes to the grammar. Our approach is resilient to
%changing compiler representations, since it requires only the input source code.
%The work presented in \cite{Namolaru2010a} automatically generates useful numerical features from compiler IR.
%Namolaru \emph{et al.} extract relational representations of programs from internal
%compiler representations in~\cite{Namolaru2010a}. By discovering and modeling relations describing patterns in compiler
%graph structures, they generate  numerical features for use in predictive modeling training. This approach closely ties
%the implementation of the predictive model to the compiler internal representations. In contrast, our approach requires
%no knowledge of the internal compiler representations, learning representations only from the program source code.
%\todo{relation space is huge, technique does not scale (they hard code limits on the complexity of discovered relations
%to maintain performance).}

%FEAST is a feature selection tool for
%compilation tasks~\cite{DBLP:journals/corr/TingTCLC16}. It automatically selects useful features from a pool of
%features provided by developers. In contrast to FEAST, our approach automatically generates and selects useful features
%without human involvement.


%% Demme, J., & Sethumadhavan, S. (2012). Approximate Graph Clustering for Program Characterization. TACO, 8(4). https://doi.org/10.1145/2086696.2086700
%Graph clustering for program characterization~\cite{Demme2012}.
%
%% Park, E., Cavazos, J., & Alvarez, M. A. (2012). Using Graph-Based Program Characterization for Predictive Modeling. In CGO. IEEE. https://doi.org/10.1145/2259016.2259042
%Using the CFG to construct feature vectors for each basic block, and lists of edges between blocks~\cite{Park2012}.
%
%% Jiang, Y., Zhang, Z. Z., Tian, K., Mao, F., Gethers, M., Shen, X., & Gao, Y. (2010). Exploiting Statistical Correlations for Proactive Prediction of Program Behaviors. CGO. https://doi.org/10.1145/1772954.1772989
%Finding correlations between dynamic program behaviours~\cite{Jiang2010}.
%

%Generative models for video~\cite{Srivastava2015}.

%% Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., & Wu, Y. (2016). Exploring the Limits of Language Modeling. arXiv:1602.02410. Retrieved from http://arxiv.org/abs/1602.02410%5Cnhttp://www.arxiv.org/pdf/1602.02410.pdf
%\cite{Jozefowicz2016a}
%
%% Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to Sequence Learning with Neural Networks. In NIPS.
%\cite{Sutskever2014}

% REDUCING THE COST OF ML

%Our use of transfer learning bridges the gap between works on continuous learning and reducing the cost of iterative compilation.
%Using active learning to minimize the cost of iterative compilation~\cite{Ogilvie2017}.
%Continuous learning of compiler heuristics~\cite{Tartara2013,Fursin2011}.
%Collaborative training data for machine learning~\cite{Cummins2016}.
%
%% TRANSFER LEARNING
%
%% Razavian, A. S., Azizpour, H., Sullivan, J., & Carlsson, S. (2014). CNN Features off-the-shelf: an Astounding Baseline for Recognition. In CVPRW. https://doi.org/10.1109/CVPRW.2014.131
%Exploring relevance of inferred features in model hidden layers~\cite{Yosinski2014}. Transfer learning is common in other domains, e.g. vision~\cite{Razavian2014,Oquab2014}. Often using the hidden layers as fixed feature extractors (by using the output of one sub-model as input to a new model), rather than using the same model structure and transferring weights (as we did).
%
%% DEEP LEARNING
%
%% Wang, H., Raj, B., & Xing, E. P. (2017). On the Origin of Deep Learning, 1â€“81. Retrieved from http://arxiv.org/abs/1702.07800
%Deep Learning is an emerging branch of machine learning, offering breakthrough domains in a number of domains~\cite{Wang2017}.
%
%Automatic inference from raw inputs in other fields. Review of representation learning~\cite{Bengio2013}. Object detection, image classification, text classification~\cite{Conneau2016}, and even to the optimizations themselves~\cite{Andrychowicz2016a}. We are the first to apply this approach to compilers.
%
%End to end training of robotic control policies~\cite{Levine2016}.
