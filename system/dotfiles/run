#!/usr/bin/env python2.7
#
# Copyright 2016-2020 Chris Cummins <chrisc.101@gmail.com>.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
import logging
import os
import socket
import sys

from argparse import ArgumentParser
from collections import deque
from time import time

import dotfiles
from util import *
from dotfiles import *


class SchedulingError(Exception): pass


def schedule_task(task_name, schedule, all_tasks, depth=1):
  """ recursively schedule a task and its dependencies """
  # Sanity check for scheduling errors:
  if depth > 1000:
    raise SchedulingError("failed to resolve schedule for task '" +
                          task_name + "' after 1000 tries")
    sys.exit(1)

  # Instantiate the task class:
  if not hasattr(dotfiles, task_name):
    raise SchedulingError("task '" + task_name + "' not found!")

  # If the task is not runnable, schedule nothing.
  task_class = getattr(dotfiles, task_name)
  if not is_runnable_task(task_class):
    return True

  task = task_class()

  # Check that all dependencies have already been scheduled:
  for dep_name in task.deps:
    if dep_name == task_name:
      raise SchedulingError("task '" + task_name + "' depends on itself")

    if dep_name not in schedule:
      # If any of the dependencies are not runnable, schedule nothing.
      if schedule_task(dep_name, schedule, all_tasks, depth + 1):
        return True

  # Schedule the task if necessary:
  if task_name not in schedule:
    schedule.append(task_name)


def get_tasks_to_run(*task_names):
  """ generate the list of task names to run """
  # Remove duplicate task names:
  task_names = set(task_names)

  # Build a list of available task names:
  all_tasks = set([type(x[1]()).__name__ for x in
                   inspect.getmembers(sys.modules[__name__], is_runnable_task)])

  # Determine the tasks which need scheduling:
  to_schedule = task_names if len(task_names) else list(all_tasks)

  # Build the schedule:
  to_schedule = deque(sorted(to_schedule))
  schedule = []
  try:
    while len(to_schedule):
      task = to_schedule.popleft()
      schedule_task(task, schedule, all_tasks)
  except SchedulingError as e:
    logging.critical("fatal: " + str(e))
    sys.exit(1)

  return deque(schedule)


def main(*args):
  """ main dotfiles method """

  # Parse arguments
  parser = ArgumentParser()
  parser.add_argument('tasks', metavar='<task>', nargs='*',
                      help="the name of tasks to run (default: all)")
  action_group = parser.add_mutually_exclusive_group()
  action_group.add_argument('-d', '--describe', action="store_true")
  action_group.add_argument('-u', '--upgrade', action='store_true')
  action_group.add_argument('-r', '--remove', action='store_true')
  action_group.add_argument('--versions', action="store_true")
  verbosity_group = parser.add_mutually_exclusive_group()
  verbosity_group.add_argument('-v', '--verbose', action='store_true')
  args = parser.parse_args(args)

  # Configure logger
  if args.verbose:
    loglevel = logging.DEBUG
  else:
    loglevel = logging.INFO
  logging.basicConfig(level=loglevel, format="%(message)s")

  # Change to root directory.
  os.chdir('/')

  # Get the list of tasks to run
  logging.debug("creating tasks list ...")
  queue = get_tasks_to_run(*args.tasks)
  done = set()
  ntasks = len(queue)

  fmt_bld, fmt_end, fmt_red = Colors.BOLD, Colors.END, Colors.RED
  platform = PLATFORM

  # --describe flag prints a description of the work to be done:
  if args.describe:
    msg = ("There are {fmt_bld}{ntasks}{fmt_end} tasks to run on {platform}:"
           .format(**vars()))
    logging.info(msg)
    for i, task_name in enumerate(queue):
      task = getattr(dotfiles, task_name)()
      j = i + 1
      desc = (task.__doc__ or "").strip()
      msg = ("[{j:2d}/{ntasks:2d}] {fmt_bld}{task}{fmt_end} ... {desc}"
             .format(**vars()))
      logging.info(msg)
      # build a list of generated files
      for file in task.genfiles:
        logging.debug("    " + os.path.abspath(os.path.expanduser(file)))

    return 0

  # --versions flag prints the specific task versions:
  if args.versions:
    for i, task_name in enumerate(queue):
      task = getattr(dotfiles, task_name)()
      for name in sorted(task.versions.keys()):
        version = task.versions[name]
        logging.info("{task_name}:{name}=={version}".format(**vars()))
    return 0

  if args.upgrade:
    task_type = "upgrade"
  elif args.remove:
    task_type = "uninstall"
  else:
    task_type = "install"

  msg = ("Running {fmt_bld}{ntasks} {task_type}{fmt_end} tasks on {platform}:"
         .format(**vars()))
  logging.info(msg)

  # Run the tasks
  errored = False
  try:
    for i, task_name in enumerate(queue):
      task = getattr(dotfiles, task_name)()

      j = i + 1
      msg = "[{j:2d}/{ntasks:2d}] {fmt_bld}{task}{fmt_end} ...".format(**vars())
      logging.info(msg)

      start_time = time()

      # Resolve and run install() method:
      get_task_method(task, task_type)()
      done.add(task)

      # Ensure that genfiles have been generated:
      if task_type == "install":
        for file in task.genfiles:
          file = os.path.abspath(os.path.expanduser(file))
          logging.debug("assert exists: '{file}'".format(**vars()))
          if not (os.path.exists(file) or
                  shell_ok("sudo test -f '{file}'".format(**vars())) or
                  shell_ok("sudo test -d '{file}'".format(**vars()))):
            raise InvalidTaskError(
                'genfile "{file}" not created'.format(**vars()))
      runtime = time() - start_time

      logging.debug("{task} task completed in {runtime:.3f}s".format(**vars()))
      sys.stdout.flush()
  except KeyboardInterrupt:
    logging.info("\ninterrupt")
    errored = True
  except Exception as e:
    e_name = type(e).__name__
    logging.error("{fmt_bld}{fmt_red}fatal error: {e_name}".format(**vars()))
    logging.error(str(e) + Colors.END)
    errored = True
    if logging.getLogger().level <= logging.DEBUG:
      raise
  finally:
    # Task teardowm
    logging.debug(Colors.BOLD + "Running teardowns" + Colors.END)
    for task in done:
      get_task_method(task, "teardown")()

      # build a list of temporary files
      tmpfiles = getattr(task, "__tmpfiles__", [])
      tmpfiles += getattr(task, "__" + PLATFORM + "_tmpfiles__", [])

      # remove any temporary files
      for file in tmpfiles:
        file = os.path.abspath(os.path.expanduser(file))
        if os.path.exists(file):
          shell("sudo rm -f '{file}'".format(file=file))

  return 1 if errored else 0


if __name__ == "__main__":
  sys.exit(main(*sys.argv[1:]))
