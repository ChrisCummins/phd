"""Import dynamic features from legacy GPGPU benchmarks driver."""
import pathlib
import tempfile
import typing
import zipfile

import pandas as pd
import sqlalchemy as sql

from experimental.deeplearning.clgen.closeness_to_grewe_features import \
  grewe_features_db as db
from gpu.libcecl import libcecl_runtime
from gpu.libcecl.proto import libcecl_pb2
from labm8.py import app
from labm8.py import fs
from labm8.py import prof
from research.grewe_2013_cgo import feature_extractor

FLAGS = app.FLAGS

app.DEFINE_input_path(
    'gpgpu_logs_zip', None,
    'Path to the logs archive generated by legacy GPGPU benchmarks runner.')
app.DEFINE_database('db', db.Database, 'sqlite://',
                    'URL of the database to import dynamic features to.')
app.DEFINE_string('device_name', None, 'The name of the OpenCL device')
app.DEFINE_string('device_type',
                  None,
                  'The device type. One of: {CPU, GPU}',
                  validator=lambda val: val in {"CPU", "GPU"} if val else True)
app.DEFINE_string('opencl_env', None, 'The name of the OpenCL environment.')
app.DEFINE_string('hostname', None, 'The name of the hostname')
app.DEFINE_boolean('extract_static_features', True, 'Extract')


def DynamicFeaturesFromKernelInvocation(
    kernel_invocation: libcecl_pb2.OpenClKernelInvocation,
    static_features_id: int) -> db.DynamicFeatures:
  return {
      'static_features_id': static_features_id,
      'gsize': kernel_invocation.global_size,
      'wgsize': kernel_invocation.local_size,
      'transferred_bytes': kernel_invocation.transferred_bytes,
      'transfer_time_ns': kernel_invocation.transfer_time_ns,
      'kernel_time_ns': kernel_invocation.kernel_time_ns,
      'run_count': 1,
  }


def GetFeatureVectors(
    source
) -> typing.Dict[str, typing.Tuple[str, feature_extractor.GreweEtAlFeatures]]:
  """Get a map from kernel name to <source, features> tuples. If feature
  extraction fails, the returned map is empty.
  """
  try:
    return {
        features.kernel_name: (source, features)
        for features in feature_extractor.ExtractFeatures(source,
                                                          timeout_seconds=5)
    }
  except feature_extractor.FeatureExtractionError:
    return {}


def GetFeatureVectorsMap(
    lines
) -> typing.Dict[str, typing.Tuple[str, feature_extractor.GreweEtAlFeatures]]:
  """Get a map from kernel name to <source, features> tuples. If feature
  extraction fails, the retured map is empty.
  """
  program_sources = []
  current_program_source: typing.Optional[typing.List[str]] = None

  # Split libcecl logs out from stderr.
  cecl_lines, stderr_lines = [], []
  in_program_source = False
  for line in lines:
    if line == 'BEGIN PROGRAM SOURCE':
      assert not in_program_source
      in_program_source = True
      current_program_source = []
    elif line == 'END PROGRAM SOURCE':
      assert in_program_source
      in_program_source = False
      program_sources.append('\n'.join(current_program_source).strip())
      current_program_source = None
    elif in_program_source:
      # Right strip program sources only, don't left strip since that would
      # lose indentation.
      current_program_source.append(line.rstrip())

  feature_vectors = {}
  for source in program_sources:
    feature_vectors.update(GetFeatureVectors(source))

  return feature_vectors


def GetStaticFeaturesId(session, origin, kernel_name, log_lines):
  ids = session.query(db.StaticFeatures.id) \
    .filter(db.StaticFeatures.origin == origin).all()
  if ids:
    return ids[0][0]

  if not FLAGS.extract_static_features:
    return None

  app.Warning('Failed to find origin `%s`', origin)

  # Try and find a matching feature vector by looking in the
  # program sources.
  with prof.Profile('check static features'):
    app.Log(1, 'checking features')
    feature_vectors = GetFeatureVectorsMap(log_lines)
  if kernel_name in feature_vectors:
    src, features = feature_vectors[kernel_name]
    static_features = db.StaticFeatures.FromSrcOriginAndFeatures(
        src, origin, features)
    session.add(static_features)
    session.commit()
    app.Log(1, 'Found new static feature vector for %s with id %d', kernel_name,
            static_features.id)
    return static_features.id

  return None


def ImportFromLegacyGpgpu(database: db.Database, logs_zip: pathlib.Path,
                          expected_devtype: str, expected_device_name: str,
                          opencl_env: str, hostname: str) -> None:
  """Import legacy GPGPU logs to database."""
  failures = []

  with database.Session() as session:
    origin_to_features_id_map = {}
    rows = []

    with tempfile.TemporaryDirectory(prefix='phd_gpgpu_') as d:
      with zipfile.ZipFile(logs_zip) as zipf:
        zipf.extractall(d)

      logs_dir = pathlib.Path(d) / 'logs'
      assert logs_dir.is_dir()

      # Directory structure of archive is:
      #     logs/<run_num>/<device_name>/<benchmark_log>.
      app.Log(1, 'Importing logs from %d runs', len(list(logs_dir.iterdir())))
      for run_dir in logs_dir.iterdir():
        for device_dir in run_dir.iterdir():
          for benchmark_log in device_dir.iterdir():
            # Re-construct the benchmark name from the file path.
            log_filename_components = benchmark_log.name.split('-')
            benchmark_suite = '-'.join(log_filename_components[:-1])
            if benchmark_suite == 'npb-3.3':
              benchmark_name, _ = log_filename_components[-1].split('.')
            else:
              benchmark_name = log_filename_components[-1]

            if benchmark_suite == 'nvidia-4.2' and benchmark_name.startswith(
                'ocl'):
              benchmark_name = benchmark_name[len('ocl'):]

            log_lines = fs.Read(benchmark_log).split('\n')
            kernel_invocations = libcecl_runtime.KernelInvocationsFromCeclLog(
                log_lines,
                # Legacy libcecl converted the nanoseconds returned by OpenCL API
                # to milliseconds float. See:
                # https://github.com/ChrisCummins/phd/blob/6e30717650380d7733d53984189ae579e19dc273/gpu/libcecl/libcecl.c#L153-L164
                nanosecond_identity=lambda s: int(float(s) * 1e6),
                expected_devtype=expected_devtype,
                expected_device_name=expected_device_name)

            for kernel_invocation in kernel_invocations:
              origin = (f'benchmarks_{benchmark_suite}:{benchmark_name}:'
                        f'{kernel_invocation.kernel_name}')
              if origin in origin_to_features_id_map:
                static_features_id = origin_to_features_id_map[origin]
              else:
                static_features_id = GetStaticFeaturesId(
                    session, origin, kernel_invocation.kernel_name, log_lines)

              origin_to_features_id_map[origin] = static_features_id
              if static_features_id:
                rows.append(
                    DynamicFeaturesFromKernelInvocation(kernel_invocation,
                                                        static_features_id))

    df = pd.DataFrame(rows)

    # Aggregate runtimes and append run_count.
    groupby_columns = ['static_features_id', 'gsize', 'wgsize']
    run_counts = df[groupby_columns +
                    ['run_count']].groupby(groupby_columns).sum()['run_count']
    df = df.groupby(groupby_columns).mean()
    df['run_count'] = run_counts
    df.reset_index(inplace=True)

    # Add missing columns.
    df['driver'] = db.DynamicFeaturesDriver.LIBCECL
    df['outcome'] = 'PASS'
    df['opencl_env'] = opencl_env
    df['hostname'] = hostname

    df.to_sql(db.DynamicFeatures.__tablename__,
              con=database.engine,
              if_exists='append',
              index=False,
              dtype={'driver': sql.Enum(db.DynamicFeaturesDriver)})

    app.Log(1, "Failed to find features for %d kernels", len(failures))
    app.Log(
        1, 'Imported %d records from %d kernels (%d distinct feature vectors)',
        len(df), len(origin_to_features_id_map),
        len(set(origin_to_features_id_map.values())))


def main():
  """Main entry point."""
  ImportFromLegacyGpgpu(FLAGS.db(),
                        FLAGS.gpgpu_logs_zip,
                        expected_devtype=FLAGS.device_type,
                        expected_device_name=FLAGS.device_name,
                        opencl_env=FLAGS.opencl_env,
                        hostname=FLAGS.hostname)


if __name__ == '__main__':
  app.Run(main)
