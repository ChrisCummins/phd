{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a shared loss variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "from third_party.py.tensorflow import tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: created directory '/tmp/phd/learn/tensorflow/tensorboard_loss'\r\n"
     ]
    }
   ],
   "source": [
    "# Where to put tensorboard logs.\n",
    "LOG_DIR = pathlib.Path('/tmp/phd/learn/tensorflow/tensorboard_loss')\n",
    "!rm -rf {LOG_DIR}\n",
    "!mkdir -pv {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the log writers.\n",
    "writer_train = tf.compat.v1.summary.FileWriter(str(LOG_DIR / 'train'))\n",
    "writer_val = tf.compat.v1.summary.FileWriter(str(LOG_DIR / 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss variable that we are going to track.\n",
    "loss_var = tf.Variable(0.0)\n",
    "\n",
    "# The loss summarizer.\n",
    "tf.summary.scalar(\"loss\", loss_var)\n",
    "\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.close()\n",
    "except:\n",
    "    pass\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've create the session, we can add the graph to the summary writer(s).\n",
    "# This enables the graph to be seen in tensorboard.\n",
    "# If we created the session before we created the summary writers, we could have\n",
    "# just passed the `graph` argument to the FileWriter, e.g.:\n",
    "#    writer_train = tf.compat.v1.summary.FileWriter(str(LOG_DIR / 'train'), graph=session.graph)\n",
    "writer_train.add_graph(session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # loss train\n",
    "    summary = session.run(summary_op, {loss_var: (1 / (i + 1)) + (np.random.rand() / 10)})\n",
    "    writer_train.add_summary(summary, i)\n",
    "    writer_train.flush()\n",
    "\n",
    "    # loss validation\n",
    "    summary = session.run(summary_op, {loss_var: (1 / (i + 1)) + (np.random.rand() / 5)})\n",
    "    writer_val.add_summary(summary, i)\n",
    "    writer_val.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using separate train / test loss variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: created directory '/tmp/phd/learn/tensorflow/tensorboard_loss'\r\n"
     ]
    }
   ],
   "source": [
    "# Where to put tensorboard logs.\n",
    "LOG_DIR = pathlib.Path('/tmp/phd/learn/tensorflow/tensorboard_loss')\n",
    "!rm -rf {LOG_DIR}\n",
    "!mkdir -pv {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the log writers.\n",
    "writer_train = tf.compat.v1.summary.FileWriter(str(LOG_DIR / 'train'))\n",
    "writer_val = tf.compat.v1.summary.FileWriter(str(LOG_DIR / 'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss variables that we are going to track.\n",
    "loss_var_train = tf.Variable(0.0)\n",
    "loss_var_val = tf.Variable(0.0)\n",
    "\n",
    "# The loss summarizer.\n",
    "train_loss_summary = tf.summary.scalar(\"train_loss\", loss_var_train)\n",
    "val_loss_summary = tf.summary.scalar(\"val_loss\", loss_var_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.close()\n",
    "except:\n",
    "    pass\n",
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    # loss train\n",
    "    summary = session.run(train_loss_summary, {loss_var_train: (1 / (i + 1)) + (np.random.rand() / 10)})\n",
    "    writer_train.add_summary(summary, i)\n",
    "    writer_train.flush()\n",
    "\n",
    "    # loss validation\n",
    "    summary = session.run(val_loss_summary, {loss_var_val: (1 / (i + 1)) + (np.random.rand() / 5)})\n",
    "    writer_val.add_summary(summary, i)\n",
    "    writer_val.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
