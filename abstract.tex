Compilers are a fundamental and trusted technology. Their role in translating software to machine code must be performed without error, while maximising the performance and efficiency of the generated code. The precedent for more rigorous validation and improved performance is well established, yet progress is challenging. Compilers comprise thousands of interacting components which must be expertly engineered and tuned, and much of the work of compiler construction has eluded automation. \diff{Furthermore, the rapid transition to heterogeneous parallelism has driven development of broad new range of accelerators which require aggressively-optimising compilers to obtain good performance. For the trend towards heterogeneity to continue, compiler construction must be made cheap.}

% The cost of these shortcomings is wasted energy, poor performance, and buggy software. What is needed is ways to lower the cost of constructing compilers.

This thesis presents new techniques that dramatically lower the cost of compiler construction, while improving robustness and performance. The enabling insight for this research is the leveraging of \emph{recurrent neural networks} to model the syntax and semantics of programming languages, enabling tasks which previously required enormous engineering effort to be automated. This is demonstrated in three challenging domains:

% This thesis presents three techniques to simplify and accelerate compiler construction.
% First, a tool for automatic performance characterisation through benchmark generation; second, a low-cost and effective fuzzer for validating correctness; third, a simple technique to address the labour intensive process of optimisation heuristic construction.

First, a generative model for compiler benchmarks is developed. This model is inferred automatically from corpora of readily available open source programs, requiring no grammar or prior knowledge of the programming language. This greatly reduces the cost of development compared to prior approaches, yet the generator produces output of such quality that professional software developers cannot distinguish generated from handwritten code. The efficacy of the generator is demonstrated by supplementing the training data of state-of-the-art predictive models for compiler optimisations. The additional fine-grained exploration of the feature space yields both an automatic improvement in heuristic performance and exposes weaknesses in the prior art which, when corrected, yields further improvements in performance.

Second, this thesis presents techniques that extend the prior approach to the domain of compiler validation. A compiler fuzzer is developed which is far simpler than the state-of-the-art, yet is effective. By learning a generative model rather than engineering a generator from scratch using a grammar, it is implemented in $100\times$ fewer lines of code than the state-of-the-art, and is capable of generating an expressive range of tests that expose bugs that prior techniques cannot. An extensive testing campaign of OpenCL compilers reveals 67 new bugs, many of which have now been fixed.

Finally, this thesis addresses the challenges of machine learning for compiler optimisations, developing methodologies for learning compiler heuristics without the need for code features. Contrasting prior approaches that require features to be expertly engineered and selected, the proposed approach learns directly over the raw textual representation of program code. Doing so outperforms state-of-the-art heuristics in two challenging optimisation domains. Additionally, the methodology permits the novel transfer of information between optimisation problems, enabling a model trained for one task to be adapted to perform another, further improving performance.
