Compilers are a fundamental and trusted technology. Their role in translating software to machine code must be performed without error, while maximising the performance and efficiency of the generated code. The precedent for more rigorous validation and improved performance is well established, yet progress is challenging.
% compiler engineering is a demanding task.
Compilers comprise thousands of interacting components which must be expertly engineered and tuned, and much of the work of compiler construction has eluded automation.
% The cost of these shortcomings is wasted energy, poor performance, and buggy software. What is needed is ways to lower the cost of constructing compilers.

% Compilers are a fundamental yet complex technology. They comprise thousands of interacting components which must be expertly engineered and tuned to both maximise performance and ensure correctness. \diff{The rapid transition to heterogeneous systems places an increasing strain on the demands of our compilers, leaving compiler developers struggling to keep up.} 

This thesis presents new techniques that dramatically lower the cost of compiler construction, while improving robustness and performance. The enabling insight for this research is the leveraging of \emph{recurrent neural networks} to model the semantics of programming languages, enabling tasks which previously required enormous engineering effort to be automated. This is demonstrated in three challenging domains:

% This thesis presents three techniques to simplify and accelerate compiler construction.
% First, a tool for automatic performance characterisation through benchmark generation; second, a low-cost and effective fuzzer for validating correctness; third, a simple technique to address the labour intensive process of optimisation heuristic construction.

First, a generative model for compiler benchmarks is developed. This model is inferred automatically from corpora of readily available open source programs, requiring no grammar or prior knowledge of the programming language. This greatly reduces the cost of development compared to prior approaches, yet the generator produces output of such quality that professional software developers cannot distinguish generated from handwritten code. The efficacy of the generator is demonstrated by supplementing the training data of state-of-the-art predictive models for compiler optimisations. The additional fine-grained exploration of the feature space yields both an automatic improvement in heuristic performance and exposes weaknesses in the prior art which, when corrected, yields further improvements in performance.

Second, this thesis presents techniques that extend the prior approach to the domain of compiler validation. A compiler fuzzer is developed which is far simpler than the state-of-the-art, yet is effective. The fuzzer is capable of generating an expressive range of tests that expose bugs that prior techniques cannot. It is implemented in $100\times$ fewer lines of code than the state-of-the-art. An extensive testing campaign of OpenCL compilers reveals 67 new bugs, many of which have now been fixed.

Finally, this thesis develops methodologies for constructing compiler heuristics without code features. Contrasting prior approaches that require code features to be expertly engineered and selected, the proposed approach learns directly over the raw textual representation of program code. Doing so outperforms state-of-the-art heuristics in two challenging optimisation domains. Additionally, the methodology permits the novel transfer of information between optimisation problems, enabling a model trained for one task to be adapted to perform another, further improving performance.
