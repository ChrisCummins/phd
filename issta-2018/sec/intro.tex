\section{Introduction}\label{sec:intro}

\noindent
Compilers should produce correct code for valid inputs, and meaningful errors for invalid inputs. Failure to do so can hinder software development or even cause catastrophic runtime errors. Still, properly testing compilers is hard. Modern optimizing compilers are large and complex programs, and their input space is huge. Hand designed suites of test programs, while important, are inadequate for covering such a large space and will not touch all parts of the compiler.

% Compilers are a fundamental, trusted technology. Bugs in them are particularly harmful. They can introduce extremely hard to identify errors in the generated binary, and are often very hard for developers to work around, particularly if their code must be portable. 

Random test case generation --- \emph{fuzzing} --- is a well established and effective method for identifying compiler bugs~\cite{Chen2014a,Chen2013,Kossatchev2005}. When fuzzing, randomly generated valid or semi-valid inputs are fed to the compiler. Any kind of unexpected behavior, including crashes, freezes, or wrong binaries, indicates a compiler bug. While crashes and freezes in the compiler are easy to detect, determining that binaries are correctly compiled is not generally possible without either developer provided validation for the particular program's behavior or a gold standard compiler from which to create reference outputs. In the absence of those, Differential Testing~\cite{McKeeman1998} can be used. The generated code and a set of inputs form a \emph{test case} which is compiled and executed on multiple \emph{testbeds}. If the test case should have deterministic behavior, but the output differs between testbeds, then a bug has been discovered.

Compiler fuzzing requires efficiently generating test cases that trigger compiler bugs. The state-of-the-art approach, CSmith~\cite{Yang2011}, generates large random programs by defining and sampling a probabilistic grammar which covers a subset of the C programming language. Through this grammar, CSmith ensures that the generated code easily passes the compiler front-end and stresses the most complex part of the compiler, the middle-end.  Complex static and dynamic analyses make sure that programs are free from undefined behavior. The programs are then differentially tested.

While CSmith has been successfully used to identify hundreds of bugs in compilers, it and similar approaches have a significant drawback. They represent a huge undertaking and require a thorough understanding of the target programming language. CSmith was developed over the course of years, and consists of over 41k lines of handwritten C++ code. By tightly coupling the generation logic with the target programming language, each feature of the grammar must be painstakingly and expertly engineered for each new target language. For example, lifting CSmith from C to OpenCL~\cite{Lidbury2015a} --- a superficially simple task --- took 9 months and an additional 8k lines of code. Given the difficulty of defining a new grammar, typically only a subset of the language is implemented.


%Differential Testing is an effective and widely studied methodology for identifying compiler bugs. %Figure~\ref{fig:difftest} shows the approach.
%A program and a set of inputs, henceforth referred to as a \emph{test case}, is compiled and executed on multiple \emph{testbeds}. If any of the compilers crash or loop indefinitely, or if the output of the programs differs between testbeds, then a potential bug has been discovered. \cc{TODO: Early work in context free grammar enumeration to text syntax analyzers~\cite{Purdom1972,Malloy2001}. These can't test past the compiler front-end. Early program generators~\cite{Zhao2009},\cite{Bryan2007}. Now, CSmith~\cite{Yang2011} and EMI testing~\cite{Le2013a} enable deeper, middle-end testing. The behavior of compilers under invalid inputs is --- to the best of our knowledge --- much less explored topic.}

%\begin{figure}
%  \centering
%  \includegraphics[width=.85\columnwidth]{img/difftest} %
%  % \vspace{-2em}%
%  \caption{%
%    Differential testing a single test case across multiple testbeds. A test case consists of a program source and its runtime parameters and data. % Outcomes may be the output of the program execution, a compiler crash, a runtime crash, or a timeout error.%
%    \cc{delete me}
%  }%
%  \label{fig:difftest}
%\end{figure}

%A probabilistic grammar is used to enumerate a large, random program, which is then compiled and executed across a number of compilers. In this manner, CSmith~\cite{Yang2011}, a random program generator for the C programming language, has been used to identify hundreds of bugs in compilers. CSmith defines a probabilistic grammar over a large subset of the C programming language, and recursively instantiates a program, using rigorous and conservative static and dynamic analysis to ensure that programs are free from undefined behavior.

%CSmith has been successfully used to identify hundreds of bugs in compilers but it represents Developing a random program generation is a huge undertaking, requiring a thorough understanding of the target programming language --- CSmith was developed over the course of years, and consists of over 40k lines of handwritten C++ code. By tightly coupling the generation logic with the target programming language, each feature of the grammar must be painstakingly and expertly engineered, and is accompanied by exponential costs in developing the static and dynamic safety checks to ensure that generated programs remain free from (or at least, are likely free from) undefined behavior. For example, lifting CSmith from C to OpenCL~\cite{Lidbury2015a} took 9 months and 8k lines of code. As such, typically only a subset of the language is implemented, and the expressiveness of the grammar is bounded by the limits of static and dynamic analysis. \cc{exhaustive testing is impossible - requiring enumeration of every sequence of characters, but grammar enumeration leaves too many bugs on the table.? }
% --- to date, important language features such as strings, dynamic memory allocation, function pointers, and recursion are unsupported.
% , despite the large overlap between C and OpenCL (which is C with extensions). This huge development cost is extended to the reduction tools too, with CLReduce~\cite{Pflanzer2016} requiring extensions to OCLgrind.

% \cc{What is needed\ldots}

What we propose is a fast, effective, and low effort approach to the generation of random programs for compiler fuzzing. Our methodology uses recent advances in deep learning to automatically construct probabilistic models of how humans write code, instead of painstakingly defining a grammar to the same end. By training a deep neural network on a corpus of handwritten code, it is able to infer both the syntax and semantics of the programming language and the common constructs and patterns. Our approach essentially frames the generation of random programs as a language modeling problem. This greatly simplifies and accelerates the process. The expressiveness of the generated programs is limited only by what is contained in the corpus, not the developer's expertise or available time. Such a corpus can readily be assembled from open source repositories.


%Using a corpus of handwritten code in a particular programming language, we use deep neural networks to automatically construct probabilistic models for how humans write programs. The neural networks, without prior knowledge, infer both the syntax and semantics of the programming language and the common constructs and patterns. By framing the generation of random programs as a language modeling problem, we greatly simplify the process of program generation, and the expressiveness of generated programs is limited only by what is contained in the corpus. Such a corpus can readily be assembled from open source repositories.

In this work we primarily target OpenCL, an open standard for programming heterogeneous systems, though our approach is largely language agnostic. We chose OpenCL for three reasons: it is an emerging standard with the challenging promise of functional portability across a diverse range of heterogeneous hardware; OpenCL is compiled ``online'', meaning that even compiler crashes and freezes may not be discovered until a product is deployed to customers; and there is already a hand written random program generator for the language to compare against. We provide preliminary results supporting DeepSmith's potential for multi-lingual compiler fuzzing.
%\cc{we need to change this last point. There's only OpenCL tester (CLSmith), vs. dozens for C/C++}.

%OpenCL is a hard programming language to test \cc{DELETE ME, not ``hard''} --- the data-parallel programming model increases the complexity of static and dynamic analysis, further limiting the expressiveness of grammar-based approaches.

%The importance of sane compiler behavior is amplified for OpenCL since it is compiled online. OpenCL code is shipped by developers to customers for compilation online. OpenCL is increasingly used in safety critical software products such as automotive vision. Segmentation faults and other runtime crashes during online compilation can disrupt the execution of safety critical processes.
%
%By design, the grammar-based approach specifically targets the compiler middle-end. Prior work \cite{McKeeman1998}
%
%This approach focuses the
%
%CSmith~\cite{Yang2011}, a popular random program generator for the C programming language, defines a probabilistic grammar over a large subset of the C programming language, and recursively instantiates a program, using rigorous and conservative static and dynamic analysis to ensure that programs are free from undefined behavior.
%
%Typically, these generated programs are many hundreds or thousands of lines long. As such, an additional test case reduction process is usually required, iteratively mutating the program in an attempt to produce a minimal working example which preserves the behavior of interest.
%
%--- to date, CLSmith does not support unions, dynamic memory allocation, strings, etc. EMI testing can simplify the production somewhat by reducing the generation only to program mutations, and deadcode insertions, but \ldots.
%
%Our observations are twofold: such rigorous and conservative methods may be artificially limiting, and that the wealth of code on the web can be used to seed the generation of codes. This paper describes our experiences in using the latter to test OpenCL.
%
%Because Csmith programs are free form undefined behavior, there is only a single interpretation. This allows oracle-less differential testing across compilers, using a voting heuristic to identify erroneous compiler outputs.
%
%Developing a random program generator is a huge undertaking, requiring expert knowledge of the target programming language. CSmith~\cite{Yang2011} was developed over a period of years, and consists of over 40k lines of hand-written C++. CSmith interleaves static analysis with code generation, and inserts runtime checks for cases where static analysis is inadequate. The ``shape'' of CSmith programs is dictated by 80 probabilities; these were extensively hand tuned so that programs ``look right''. Beyond this, the expressiveness of CSmith-generated programs is
%
%\cc{We propose \ldots}
%
%In contrast to probabilistic grammar-based approaches, our approach is programming language agnostic, requiring only a corpus of sample programs in the intended programming language. Such corpuses can be readily be assembled from GitHub. We then use state-of-the-art deep learning techniques to automatically infer the semantics and common usage of a programming language. Learning and sampling an LSTM model requires less than a 100 line of Python script, and contains no programming language-specific logic. The expressiveness of synthesized programs is governed by the corpus; unlike with grammar-based approach, in which every new language feature must be engineered. E.g. to date, CSmith does not support floating points, unions, strings, dynamic memory allocation, function pointers, or recursion. Additionally, all integer arithmetic is wrapped in ``safe math'' macros.
%
%We also, for the first time, provide a means of testing compiler behaviour under plausibly-invalid input conditions. We generate plausible but ill-formed inputs. Prior work used random ASCII sequences to identify compiler front-end bugs~\cite{McKeeman1998}. By mimicking hand written code, our technique is capable of discovering bugs further within the compiler, including middle-end and even code generation.
%
%The design trade-off of our approach is that unstructured, syntactic-level synthesis of program code removes the guarantee that programs are free from undefined behavior, a property which previous approaches have relied upon. In practice, we found this requirement to be too conservative. In testing XXX cases, we discovered only XX cases where a program without a single interpretation was not trivially detectable through differential testing and presented a false positive.
%% Reference: UB in C https://blog.regehr.org/archives/1520
%% Reference: C99 spec appendix J2 - list of UBs
%% OpenCL un-undefines some of those behaviours (e.g. it provides conversion functions between data types), but also adds to them.

% \noindent
We make the following contributions:
%
\begin{itemize}
\item a novel, automatic, and fast approach for the generation of expressive random programs for compiler fuzzing. We \emph{infer} programming language syntax, structure, and use from real-world examples, not through an expert-defined grammar. Our system needs two orders of magnitude less code than the state-of–the-art, and takes less than a day to train; % CLSmith requires expert-driven development for every language feature supported. 40+k lines of C++ vs a few hundred lines of Python.

\item we discover a similar number of bugs as the state-of–the-art, but also find bugs which prior work cannot, covering more components of the compiler;
% e.g. ill-formed

\item in modeling real handwritten code, our test cases are more interpretable than other approaches. Average test case size is two orders of magnitude smaller than state-of-the-art, without any expensive reduction process.
\end{itemize}
