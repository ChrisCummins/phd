\chapter{Conclusions}
\label{chap:conclusions}

\section{Contributions}

This section summarises the main contributions of this thesis for XXX.

\subsection{Workload Characterisation}

\subsection{Compiler Optimisations}

\subsection{Compiler Testing}

\section{Critical Analysis}

\subsection{Limitations of Generative Models}

Extensibility to other languages largely untested.

Generating multi-function programs.

% TODO(cec): CGO'17 limitations

Our new approach enables the synthesis of more human-like programs than current state-of-the-art program generators, and without the expert guidance required by template based generators, but it has limitations. Our method of seeding the language models with the start of a function means that we cannot support user defined types, or calls to user-defined functions. This means that we only consider scalars and arrays as inputs; while 6 (2.3\%) of the benchmark kernels from Table~\ref{tab:benchmarks} use irregular data types as inputs. We will address this limitation through recursive program synthesis, whereby a call to a user-defined function or unrecognised type will trigger candidate functions and type definitions to be synthesised. Currently we only run single-kernel benchmarks. We will extend the host driver to explore multi-kernel schedules and interleaving of kernel executions. Our host driver generates data sets from uniform random distributions, as do many of the benchmark suites. For cases where non-uniform inputs are required (e.g. profile-directed feedback), an alternate methodology for generating inputs must be adopted.


\subsection{Limitations of Sequential Classification}

\section{Future Work}

\todo[inline]{Graph-level representations with RNNS~\cite{Jin2018}. Graph surveys~\cite{Li2018a,Wu2018}.}

\todo[inline]{Table of GitHub corpus size by programming language. There's room for machine learning in lots of languages! E.g. Haskell, Java, C/C++, Solidity, Python, OpenCL}